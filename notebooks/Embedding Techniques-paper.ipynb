{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier,RandomForestRegressor, BaggingClassifier, AdaBoostClassifier, VotingClassifier, VotingRegressor\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from scipy import sparse\n",
    "from tqdm import tqdm_notebook\n",
    "from nltk import word_tokenize\n",
    "from pymagnitude import *\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models import Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../csv/train108.csv').sample(frac=1)\n",
    "docs = df['doc_text']\n",
    "y = df['labels']\n",
    "X = docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(X,y):\n",
    "    values = {}\n",
    "    scoring = {\n",
    "        'acc':'accuracy',\n",
    "        'f1':'f1_macro'\n",
    "    }\n",
    "    clf = MLPClassifier(n_iter_no_change=50, max_iter=10000,hidden_layer_sizes=(512, ))\n",
    "    res = cross_validate(clf, X, y, cv=10,  return_train_score=True, scoring=scoring) \n",
    "    acc = res['test_acc']\n",
    "    f1 = res['test_f1']\n",
    "    print(\"mlp Accuracy: %0.2f (+/- %0.2f)\" % (acc.mean(), acc.std()))\n",
    "    print(\"mlp f1: %0.2f (+/- %0.2f)\" % (f1.mean(), f1.std()))\n",
    "    print()\n",
    "    values['mlp_acc'] = acc.mean()\n",
    "    values['mlp_f1'] = f1.mean()\n",
    "\n",
    "    clf = BernoulliNB()\n",
    "    res = cross_validate(clf, X, y, cv=10,  return_train_score=True, scoring=scoring)  \n",
    "    acc = res['test_acc']\n",
    "    f1 = res['test_f1']\n",
    "    print(\"NB Accuracy: %0.2f (+/- %0.2f)\" % (acc.mean(), acc.std()))\n",
    "    print(\"NB f1: %0.2f (+/- %0.2f)\" % (f1.mean(), f1.std()))\n",
    "    print()\n",
    "    values['nb_acc'] = acc.mean()\n",
    "    values['nb_f1'] = f1.mean()\n",
    "\n",
    "    \n",
    "    clf = LogisticRegression(max_iter=1000)\n",
    "    res = cross_validate(clf, X, y, cv=10,  return_train_score=True, scoring=scoring) \n",
    "    acc = res['test_acc']\n",
    "    f1 = res['test_f1']\n",
    "    print(\"logistic reg Accuracy: %0.2f (+/- %0.2f)\" % (acc.mean(), acc.std()))\n",
    "    print(\"logistic reg f1: %0.2f (+/- %0.2f)\" % (f1.mean(), f1.std()))\n",
    "    print()\n",
    "    values['lr_acc'] = acc.mean()\n",
    "    values['lr_f1'] = f1.mean()\n",
    "\n",
    "    \n",
    "    clf = svm.SVC(kernel='poly', degree=2)\n",
    "    res = cross_validate(clf, X, y, cv=10,  return_train_score=True, scoring=scoring)  \n",
    "    acc = res['test_acc']\n",
    "    f1 = res['test_f1']\n",
    "    print(\"svm Accuracy: %0.2f (+/- %0.2f)\" % (acc.mean(), acc.std()))\n",
    "    print(\"svm f1: %0.2f (+/- %0.2f)\" % (f1.mean(), f1.std()))\n",
    "    print()\n",
    "    values['svm_acc'] = acc.mean()\n",
    "    values['svm_f1'] = f1.mean()\n",
    "\n",
    "    \n",
    "    clf = RandomForestClassifier(n_estimators=1000,n_jobs=-1)\n",
    "    res = cross_validate(clf, X, y, cv=10,  return_train_score=True, scoring=scoring)  \n",
    "    acc = res['test_acc']\n",
    "    f1 = res['test_f1']\n",
    "    print(\"random forest Accuracy: %0.2f (+/- %0.2f)\" % (acc.mean(), acc.std()))\n",
    "    print(\"random forest f1: %0.2f (+/- %0.2f)\" % (f1.mean(), f1.std()))\n",
    "    print()\n",
    "    values['rf_acc'] = acc.mean()\n",
    "    values['rf_f1'] = f1.mean()\n",
    "\n",
    "    return values\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reg_results(X, y):\n",
    "    regr = LinearRegression(normalize=True)\n",
    "#     res = cross_validate(clf, X, y, cv=10)\n",
    "    scores = cross_val_score(regr, X, y, scoring='neg_root_mean_squared_error', cv=10)\n",
    "    print(\"linear regression RMSE:\",-scores.mean())\n",
    "    print()\n",
    "    \n",
    "    regr = RandomForestRegressor()\n",
    "#     res = cross_validate(clf, X, y, cv=10) \n",
    "    scores = cross_val_score(regr, X, y, scoring='neg_root_mean_squared_error', cv=10)\n",
    "    print(\"Random Forest reg RMSE:\",-scores.mean())\n",
    "    print()\n",
    "    \n",
    "    \n",
    "    from sklearn import svm\n",
    "    regr = svm.SVR()\n",
    "#     res = cross_validate(clf, X, y, cv=10) \n",
    "    scores = cross_val_score(regr, X, y, scoring='neg_root_mean_squared_error', cv=10)\n",
    "    print(\"SVM RMSE:\",-scores.mean())\n",
    "    print()\n",
    "    \n",
    "    regr = MLPRegressor(max_iter=10000,learning_rate='constant')\n",
    "#     res = cross_validate(clf, X, y, cv=10) \n",
    "    scores = cross_val_score(regr, X, y, scoring='neg_root_mean_squared_error', cv=10)\n",
    "    print(\"MLP RMSE:\",-scores.mean())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikamanth/anaconda3/envs/torch/lib/python3.6/site-packages/ipykernel_launcher.py:10: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0622a6b267cc4a3bb87ae89165f1dbe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=108.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mlp Accuracy: 0.82 (+/- 0.09)\n",
      "mlp f1: 0.82 (+/- 0.09)\n",
      "\n",
      "NB Accuracy: 0.75 (+/- 0.09)\n",
      "NB f1: 0.74 (+/- 0.09)\n",
      "\n",
      "logistic reg Accuracy: 0.74 (+/- 0.08)\n",
      "logistic reg f1: 0.74 (+/- 0.08)\n",
      "\n",
      "svm Accuracy: 0.82 (+/- 0.10)\n",
      "svm f1: 0.82 (+/- 0.10)\n",
      "\n",
      "random forest Accuracy: 0.82 (+/- 0.09)\n",
      "random forest f1: 0.82 (+/- 0.09)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mlp_acc': 0.8227272727272729,\n",
       " 'mlp_f1': 0.8171922521922523,\n",
       " 'nb_acc': 0.7481818181818182,\n",
       " 'nb_f1': 0.7423265623265622,\n",
       " 'lr_acc': 0.739090909090909,\n",
       " 'lr_f1': 0.7378787878787879,\n",
       " 'svm_acc': 0.8218181818181819,\n",
       " 'svm_f1': 0.8182822732822734,\n",
       " 'rf_acc': 0.8227272727272729,\n",
       " 'rf_f1': 0.8207264957264957}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#word2vec\n",
    "from tqdm import tqdm_notebook\n",
    "from nltk import word_tokenize\n",
    "from pymagnitude import *\n",
    "\n",
    "\n",
    "glove = Magnitude(\"../downloads/GoogleNews-vectors-negative300.magnitude\")\n",
    "def avg_glove(x):\n",
    "    vectors = []\n",
    "    for title in tqdm_notebook(x):\n",
    "        vectors.append(np.average(glove.query(word_tokenize(title)), axis = 0))\n",
    "    return np.array(vectors)\n",
    "\n",
    "x = avg_glove(X)\n",
    "# x_test = avg_glove(test)\n",
    "\n",
    "get_results(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikamanth/anaconda3/envs/torch/lib/python3.6/site-packages/ipykernel_launcher.py:14: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc4af139bb8b41bea0948ae100ac8404",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=108.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mlp Accuracy: 0.83 (+/- 0.07)\n",
      "mlp f1: 0.83 (+/- 0.08)\n",
      "\n",
      "NB Accuracy: 0.76 (+/- 0.12)\n",
      "NB f1: 0.75 (+/- 0.12)\n",
      "\n",
      "logistic reg Accuracy: 0.79 (+/- 0.12)\n",
      "logistic reg f1: 0.78 (+/- 0.12)\n",
      "\n",
      "svm Accuracy: 0.81 (+/- 0.09)\n",
      "svm f1: 0.80 (+/- 0.09)\n",
      "\n",
      "random forest Accuracy: 0.81 (+/- 0.12)\n",
      "random forest f1: 0.80 (+/- 0.12)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mlp_acc': 0.8327272727272726,\n",
       " 'mlp_f1': 0.82519314019314,\n",
       " 'nb_acc': 0.759090909090909,\n",
       " 'nb_f1': 0.7549550449550448,\n",
       " 'lr_acc': 0.7863636363636364,\n",
       " 'lr_f1': 0.7835372960372962,\n",
       " 'svm_acc': 0.8054545454545454,\n",
       " 'svm_f1': 0.8036557886557885,\n",
       " 'rf_acc': 0.8054545454545454,\n",
       " 'rf_f1': 0.8035120435120435}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#word2vec\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "glove = Magnitude(\"../downloads/GoogleNews-vectors-negative300.magnitude\")\n",
    "\n",
    "x = docs\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf.fit(x)\n",
    "# Now lets create a dict so that for every word in the corpus we have a corresponding IDF value\n",
    "idf_dict = dict(zip(tfidf.get_feature_names(), tfidf.idf_))\n",
    "# Same as Avg Glove except instead of doing a regular average, we'll use the IDF values as weights.\n",
    "def tfidf_glove(df):\n",
    "    vectors = []\n",
    "    for title in tqdm_notebook(df):\n",
    "        glove_vectors = glove.query(word_tokenize(title))\n",
    "        weights = [idf_dict.get(word, 1) for word in word_tokenize(title)]\n",
    "        vectors.append(np.average(glove_vectors, axis = 0, weights = weights))\n",
    "    return np.array(vectors)\n",
    "x = tfidf_glove(X)\n",
    "# x_test = tfidf_glove(test)\n",
    "\n",
    "get_results(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikamanth/anaconda3/envs/torch/lib/python3.6/site-packages/ipykernel_launcher.py:10: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ffd187b9ce5428ca6df6816d603230f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=108.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mlp Accuracy: 0.80 (+/- 0.11)\n",
      "mlp f1: 0.79 (+/- 0.11)\n",
      "\n",
      "NB Accuracy: 0.67 (+/- 0.08)\n",
      "NB f1: 0.65 (+/- 0.09)\n",
      "\n",
      "logistic reg Accuracy: 0.74 (+/- 0.13)\n",
      "logistic reg f1: 0.74 (+/- 0.13)\n",
      "\n",
      "svm Accuracy: 0.76 (+/- 0.14)\n",
      "svm f1: 0.76 (+/- 0.15)\n",
      "\n",
      "random forest Accuracy: 0.82 (+/- 0.12)\n",
      "random forest f1: 0.81 (+/- 0.13)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mlp_acc': 0.7963636363636364,\n",
       " 'mlp_f1': 0.7895773670773669,\n",
       " 'nb_acc': 0.6672727272727274,\n",
       " 'nb_f1': 0.6512873237873238,\n",
       " 'lr_acc': 0.74,\n",
       " 'lr_f1': 0.7364685314685314,\n",
       " 'svm_acc': 0.759090909090909,\n",
       " 'svm_f1': 0.7558624708624707,\n",
       " 'rf_acc': 0.8154545454545454,\n",
       " 'rf_f1': 0.8125213675213676}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#glove\n",
    "from tqdm import tqdm_notebook\n",
    "from nltk import word_tokenize\n",
    "from pymagnitude import *\n",
    "\n",
    "\n",
    "glove = Magnitude(\"../downloads/glove.6B.100d.magnitude\")\n",
    "def avg_glove(x):\n",
    "    vectors = []\n",
    "    for title in tqdm_notebook(x):\n",
    "        vectors.append(np.average(glove.query(word_tokenize(title)), axis = 0))\n",
    "    return np.array(vectors)\n",
    "\n",
    "x = avg_glove(X)\n",
    "# x_test = avg_glove(test)\n",
    "\n",
    "get_results(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikamanth/anaconda3/envs/torch/lib/python3.6/site-packages/ipykernel_launcher.py:14: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad535d9c11e84a3eba7b0a4b3c31d4f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=108.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mlp Accuracy: 0.84 (+/- 0.10)\n",
      "mlp f1: 0.84 (+/- 0.11)\n",
      "\n",
      "NB Accuracy: 0.69 (+/- 0.15)\n",
      "NB f1: 0.69 (+/- 0.15)\n",
      "\n",
      "logistic reg Accuracy: 0.70 (+/- 0.10)\n",
      "logistic reg f1: 0.70 (+/- 0.10)\n",
      "\n",
      "svm Accuracy: 0.79 (+/- 0.15)\n",
      "svm f1: 0.78 (+/- 0.15)\n",
      "\n",
      "random forest Accuracy: 0.81 (+/- 0.13)\n",
      "random forest f1: 0.81 (+/- 0.13)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mlp_acc': 0.8427272727272725,\n",
       " 'mlp_f1': 0.8371750471750472,\n",
       " 'nb_acc': 0.6936363636363636,\n",
       " 'nb_f1': 0.6864485514485514,\n",
       " 'lr_acc': 0.7027272727272728,\n",
       " 'lr_f1': 0.6969355644355644,\n",
       " 'svm_acc': 0.7872727272727273,\n",
       " 'svm_f1': 0.7838691863691863,\n",
       " 'rf_acc': 0.8136363636363635,\n",
       " 'rf_f1': 0.8122649572649572}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#glove\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "glove = Magnitude(\"../downloads/glove.6B.100d.magnitude\")\n",
    "\n",
    "x = docs\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf.fit(x)\n",
    "# Now lets create a dict so that for every word in the corpus we have a corresponding IDF value\n",
    "idf_dict = dict(zip(tfidf.get_feature_names(), tfidf.idf_))\n",
    "# Same as Avg Glove except instead of doing a regular average, we'll use the IDF values as weights.\n",
    "def tfidf_glove(df):\n",
    "    vectors = []\n",
    "    for title in tqdm_notebook(df):\n",
    "        glove_vectors = glove.query(word_tokenize(title))\n",
    "        weights = [idf_dict.get(word, 1) for word in word_tokenize(title)]\n",
    "        vectors.append(np.average(glove_vectors, axis = 0, weights = weights))\n",
    "    return np.array(vectors)\n",
    "x = tfidf_glove(X)\n",
    "# x_test = tfidf_glove(test)\n",
    "\n",
    "get_results(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikamanth/anaconda3/envs/torch/lib/python3.6/site-packages/ipykernel_launcher.py:14: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b759f24412a484d89316e28ed04c5f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=108.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mlp Accuracy: 0.80 (+/- 0.06)\n",
      "mlp f1: 0.79 (+/- 0.06)\n",
      "\n",
      "NB Accuracy: 0.82 (+/- 0.09)\n",
      "NB f1: 0.81 (+/- 0.09)\n",
      "\n",
      "logistic reg Accuracy: 0.75 (+/- 0.13)\n",
      "logistic reg f1: 0.75 (+/- 0.13)\n",
      "\n",
      "svm Accuracy: 0.80 (+/- 0.12)\n",
      "svm f1: 0.79 (+/- 0.12)\n",
      "\n",
      "random forest Accuracy: 0.84 (+/- 0.12)\n",
      "random forest f1: 0.84 (+/- 0.13)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mlp_acc': 0.7954545454545455,\n",
       " 'mlp_f1': 0.7883888333888335,\n",
       " 'nb_acc': 0.8154545454545454,\n",
       " 'nb_f1': 0.8136033411033411,\n",
       " 'lr_acc': 0.75,\n",
       " 'lr_f1': 0.7456615606615606,\n",
       " 'svm_acc': 0.7963636363636364,\n",
       " 'svm_f1': 0.7939588189588189,\n",
       " 'rf_acc': 0.8418181818181818,\n",
       " 'rf_f1': 0.8392385392385391}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#glove\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "glove = Magnitude(\"../downloads/glove.840B.300d.magnitude\")\n",
    "\n",
    "x = docs\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf.fit(x)\n",
    "# Now lets create a dict so that for every word in the corpus we have a corresponding IDF value\n",
    "idf_dict = dict(zip(tfidf.get_feature_names(), tfidf.idf_))\n",
    "# Same as Avg Glove except instead of doing a regular average, we'll use the IDF values as weights.\n",
    "def tfidf_glove(df):\n",
    "    vectors = []\n",
    "    for title in tqdm_notebook(df):\n",
    "        glove_vectors = glove.query(word_tokenize(title))\n",
    "        weights = [idf_dict.get(word, 1) for word in word_tokenize(title)]\n",
    "        vectors.append(np.average(glove_vectors, axis = 0, weights = weights))\n",
    "    return np.array(vectors)\n",
    "x = tfidf_glove(X)\n",
    "# x_test = tfidf_glove(test)\n",
    "\n",
    "get_results(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikamanth/anaconda3/envs/torch/lib/python3.6/site-packages/ipykernel_launcher.py:10: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b5a568c234b4303b89eb5f29773ab5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=108.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mlp Accuracy: 0.86 (+/- 0.11)\n",
      "mlp f1: 0.86 (+/- 0.11)\n",
      "\n",
      "NB Accuracy: 0.83 (+/- 0.12)\n",
      "NB f1: 0.83 (+/- 0.12)\n",
      "\n",
      "logistic reg Accuracy: 0.77 (+/- 0.12)\n",
      "logistic reg f1: 0.76 (+/- 0.12)\n",
      "\n",
      "svm Accuracy: 0.81 (+/- 0.14)\n",
      "svm f1: 0.80 (+/- 0.14)\n",
      "\n",
      "random forest Accuracy: 0.84 (+/- 0.13)\n",
      "random forest f1: 0.84 (+/- 0.13)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mlp_acc': 0.860909090909091,\n",
       " 'mlp_f1': 0.8577580752580752,\n",
       " 'nb_acc': 0.8336363636363636,\n",
       " 'nb_f1': 0.8322649572649572,\n",
       " 'lr_acc': 0.7681818181818182,\n",
       " 'lr_f1': 0.7631152181152181,\n",
       " 'svm_acc': 0.8054545454545454,\n",
       " 'svm_f1': 0.8038383838383838,\n",
       " 'rf_acc': 0.8418181818181818,\n",
       " 'rf_f1': 0.8406487956487956}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fasttext\n",
    "from tqdm import tqdm_notebook\n",
    "from nltk import word_tokenize\n",
    "from pymagnitude import *\n",
    "\n",
    "\n",
    "glove = Magnitude(\"../downloads/wiki-news-300d-1M.magnitude\")\n",
    "def avg_glove(x):\n",
    "    vectors = []\n",
    "    for title in tqdm_notebook(x):\n",
    "        vectors.append(np.average(glove.query(word_tokenize(title)), axis = 0))\n",
    "    return np.array(vectors)\n",
    "\n",
    "x = avg_glove(X)\n",
    "# x_test = avg_glove(test)\n",
    "\n",
    "get_results(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikamanth/anaconda3/envs/torch/lib/python3.6/site-packages/ipykernel_launcher.py:14: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3158e8a4929a43859494e0486cbb577f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=108.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mlp Accuracy: 0.83 (+/- 0.08)\n",
      "mlp f1: 0.83 (+/- 0.08)\n",
      "\n",
      "NB Accuracy: 0.81 (+/- 0.15)\n",
      "NB f1: 0.81 (+/- 0.15)\n",
      "\n",
      "logistic reg Accuracy: 0.78 (+/- 0.12)\n",
      "logistic reg f1: 0.77 (+/- 0.12)\n",
      "\n",
      "svm Accuracy: 0.79 (+/- 0.12)\n",
      "svm f1: 0.79 (+/- 0.12)\n",
      "\n",
      "random forest Accuracy: 0.81 (+/- 0.14)\n",
      "random forest f1: 0.81 (+/- 0.15)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mlp_acc': 0.8327272727272728,\n",
       " 'mlp_f1': 0.8280142080142079,\n",
       " 'nb_acc': 0.8136363636363637,\n",
       " 'nb_f1': 0.8125679875679875,\n",
       " 'lr_acc': 0.7763636363636364,\n",
       " 'lr_f1': 0.774067599067599,\n",
       " 'svm_acc': 0.7945454545454546,\n",
       " 'svm_f1': 0.792082362082362,\n",
       " 'rf_acc': 0.8127272727272727,\n",
       " 'rf_f1': 0.8113636363636363}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fasttext\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "glove = Magnitude(\"../downloads/wiki-news-300d-1M.magnitude\")\n",
    "\n",
    "x = docs\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf.fit(x)\n",
    "# Now lets create a dict so that for every word in the corpus we have a corresponding IDF value\n",
    "idf_dict = dict(zip(tfidf.get_feature_names(), tfidf.idf_))\n",
    "# Same as Avg Glove except instead of doing a regular average, we'll use the IDF values as weights.\n",
    "def tfidf_glove(df):\n",
    "    vectors = []\n",
    "    for title in tqdm_notebook(df):\n",
    "        glove_vectors = glove.query(word_tokenize(title))\n",
    "        weights = [idf_dict.get(word, 1) for word in word_tokenize(title)]\n",
    "        vectors.append(np.average(glove_vectors, axis = 0, weights = weights))\n",
    "    return np.array(vectors)\n",
    "x = tfidf_glove(X)\n",
    "# x_test = tfidf_glove(test)\n",
    "\n",
    "get_results(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikamanth/anaconda3/envs/torch/lib/python3.6/site-packages/ipykernel_launcher.py:10: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e29d538469c42618e414c4b2eded1e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=108.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikamanth/anaconda3/envs/torch/lib/python3.6/site-packages/pymagnitude/third_party/allennlp/nn/util.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
      "  index_range = sequence_lengths.new_tensor(torch.arange(0, len(sequence_lengths)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mlp Accuracy: 0.81 (+/- 0.09)\n",
      "mlp f1: 0.81 (+/- 0.09)\n",
      "\n",
      "NB Accuracy: 0.79 (+/- 0.13)\n",
      "NB f1: 0.79 (+/- 0.14)\n",
      "\n",
      "logistic reg Accuracy: 0.82 (+/- 0.12)\n",
      "logistic reg f1: 0.82 (+/- 0.12)\n",
      "\n",
      "svm Accuracy: 0.81 (+/- 0.14)\n",
      "svm f1: 0.81 (+/- 0.14)\n",
      "\n",
      "random forest Accuracy: 0.82 (+/- 0.13)\n",
      "random forest f1: 0.82 (+/- 0.13)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mlp_acc': 0.8145454545454545,\n",
       " 'mlp_f1': 0.8115112665112664,\n",
       " 'nb_acc': 0.7881818181818182,\n",
       " 'nb_f1': 0.7856099456099456,\n",
       " 'lr_acc': 0.8236363636363636,\n",
       " 'lr_f1': 0.822012432012432,\n",
       " 'svm_acc': 0.8145454545454545,\n",
       " 'svm_f1': 0.8126029526029525,\n",
       " 'rf_acc': 0.8236363636363636,\n",
       " 'rf_f1': 0.8224747474747474}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#elmo\n",
    "from tqdm import tqdm_notebook\n",
    "from nltk import word_tokenize\n",
    "from pymagnitude import *\n",
    "\n",
    "\n",
    "glove = Magnitude(\"../downloads/elmo_2x1024_128_2048cnn_1xhighway_weights.magnitude\")\n",
    "def avg_glove(x):\n",
    "    vectors = []\n",
    "    for title in tqdm_notebook(x):\n",
    "        vectors.append(np.average(glove.query(word_tokenize(title)), axis = 0))\n",
    "    return np.array(vectors)\n",
    "\n",
    "x = avg_glove(X)\n",
    "# x_test = avg_glove(test)\n",
    "\n",
    "get_results(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikamanth/anaconda3/envs/torch/lib/python3.6/site-packages/ipykernel_launcher.py:14: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6555adda75749d0953ad2a427486137",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=108.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikamanth/anaconda3/envs/torch/lib/python3.6/site-packages/pymagnitude/third_party/allennlp/nn/util.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
      "  index_range = sequence_lengths.new_tensor(torch.arange(0, len(sequence_lengths)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "mlp Accuracy: 0.85 (+/- 0.08)\n",
      "mlp f1: 0.85 (+/- 0.08)\n",
      "\n",
      "NB Accuracy: 0.79 (+/- 0.14)\n",
      "NB f1: 0.78 (+/- 0.14)\n",
      "\n",
      "logistic reg Accuracy: 0.85 (+/- 0.10)\n",
      "logistic reg f1: 0.85 (+/- 0.10)\n",
      "\n",
      "svm Accuracy: 0.83 (+/- 0.12)\n",
      "svm f1: 0.83 (+/- 0.13)\n",
      "\n",
      "random forest Accuracy: 0.84 (+/- 0.14)\n",
      "random forest f1: 0.84 (+/- 0.15)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mlp_acc': 0.850909090909091,\n",
       " 'mlp_f1': 0.8478163503163503,\n",
       " 'nb_acc': 0.7854545454545454,\n",
       " 'nb_f1': 0.7833255633255634,\n",
       " 'lr_acc': 0.8509090909090908,\n",
       " 'lr_f1': 0.8478671328671329,\n",
       " 'svm_acc': 0.8327272727272726,\n",
       " 'svm_f1': 0.8300038850038849,\n",
       " 'rf_acc': 0.8427272727272728,\n",
       " 'rf_f1': 0.8402564102564101}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#elmo\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "glove = Magnitude(\"../downloads/elmo_2x1024_128_2048cnn_1xhighway_weights.magnitude\")\n",
    "\n",
    "x = docs\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf.fit(x)\n",
    "# Now lets create a dict so that for every word in the corpus we have a corresponding IDF value\n",
    "idf_dict = dict(zip(tfidf.get_feature_names(), tfidf.idf_))\n",
    "# Same as Avg Glove except instead of doing a regular average, we'll use the IDF values as weights.\n",
    "def tfidf_glove(df):\n",
    "    vectors = []\n",
    "    for title in tqdm_notebook(df):\n",
    "        glove_vectors = glove.query(word_tokenize(title))\n",
    "        weights = [idf_dict.get(word, 1) for word in word_tokenize(title)]\n",
    "        vectors.append(np.average(glove_vectors, axis = 0, weights = weights))\n",
    "    return np.array(vectors)\n",
    "x = tfidf_glove(X)\n",
    "# x_test = tfidf_glove(test)\n",
    "\n",
    "get_results(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../csv/train108.csv').sample(frac=1)\n",
    "docs = df['doc_text']\n",
    "y = df['mmse']\n",
    "X = docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikamanth/anaconda3/envs/torch/lib/python3.6/site-packages/ipykernel_launcher.py:10: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ffae85789534ec88039a53938ea33e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=108.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "linear regression RMSE: 5.406521775295223\n",
      "\n",
      "Random Forest reg RMSE: 5.234289316501789\n",
      "\n",
      "SVM RMSE: 7.00252550820454\n",
      "\n",
      "MLP RMSE: 5.065448647663843\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikamanth/anaconda3/envs/torch/lib/python3.6/site-packages/ipykernel_launcher.py:32: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42ad923ed9b44711a0626e18e60fb750",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=108.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "linear regression RMSE: 5.149768098763781\n",
      "\n",
      "Random Forest reg RMSE: 5.1688211668239985\n",
      "\n",
      "SVM RMSE: 6.966570331976636\n",
      "\n",
      "MLP RMSE: 4.728106000379271\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikamanth/anaconda3/envs/torch/lib/python3.6/site-packages/ipykernel_launcher.py:51: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e68d181d58d94d09a36ac8be2070db43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=108.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "linear regression RMSE: 15.962882994611814\n",
      "\n",
      "Random Forest reg RMSE: 4.881603892305163\n",
      "\n",
      "SVM RMSE: 7.36628077963842\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikamanth/anaconda3/envs/torch/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/nikamanth/anaconda3/envs/torch/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/nikamanth/anaconda3/envs/torch/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/nikamanth/anaconda3/envs/torch/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/nikamanth/anaconda3/envs/torch/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP RMSE: 5.4584604422641245\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikamanth/anaconda3/envs/torch/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "/home/nikamanth/anaconda3/envs/torch/lib/python3.6/site-packages/ipykernel_launcher.py:73: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78d52541cd20439abf79fc037ec6e98a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=108.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "linear regression RMSE: 23.92389723077356\n",
      "\n",
      "Random Forest reg RMSE: 5.176854151995177\n",
      "\n",
      "SVM RMSE: 7.354001145463114\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikamanth/anaconda3/envs/torch/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (10000) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP RMSE: 5.588874347232781\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikamanth/anaconda3/envs/torch/lib/python3.6/site-packages/ipykernel_launcher.py:96: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c98208321c546f7a318a97efeca3a50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=108.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "linear regression RMSE: 7.019259460628136\n",
      "\n",
      "Random Forest reg RMSE: 5.141349213688855\n",
      "\n",
      "SVM RMSE: 7.190926116104729\n",
      "\n",
      "MLP RMSE: 5.620737409912522\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikamanth/anaconda3/envs/torch/lib/python3.6/site-packages/ipykernel_launcher.py:115: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4451798d0d694af5815961400f75f392",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=108.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "linear regression RMSE: 5.085972760797771\n",
      "\n",
      "Random Forest reg RMSE: 4.6988517154620215\n",
      "\n",
      "SVM RMSE: 7.42920338887552\n",
      "\n",
      "MLP RMSE: 4.815987303617524\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikamanth/anaconda3/envs/torch/lib/python3.6/site-packages/ipykernel_launcher.py:137: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "914c9041e91f4ffeb842d281c4cf9f22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=108.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "linear regression RMSE: 5.289475788462676\n",
      "\n",
      "Random Forest reg RMSE: 5.245529855939969\n",
      "\n",
      "SVM RMSE: 7.40265455156096\n",
      "\n",
      "MLP RMSE: 4.834287443452469\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikamanth/anaconda3/envs/torch/lib/python3.6/site-packages/ipykernel_launcher.py:156: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e74ea68c525f4f5185f743f342f257d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=108.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikamanth/anaconda3/envs/torch/lib/python3.6/site-packages/pymagnitude/third_party/allennlp/nn/util.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
      "  index_range = sequence_lengths.new_tensor(torch.arange(0, len(sequence_lengths)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "linear regression RMSE: 4.806956793257003\n",
      "\n",
      "Random Forest reg RMSE: 4.738004736807781\n",
      "\n",
      "SVM RMSE: 6.96667593701756\n",
      "\n",
      "MLP RMSE: 7.9392103562164476\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikamanth/anaconda3/envs/torch/lib/python3.6/site-packages/ipykernel_launcher.py:178: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4019a4d45042419da4e28c375ba1c929",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=108.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nikamanth/anaconda3/envs/torch/lib/python3.6/site-packages/pymagnitude/third_party/allennlp/nn/util.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than tensor.new_tensor(sourceTensor).\n",
      "  index_range = sequence_lengths.new_tensor(torch.arange(0, len(sequence_lengths)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "linear regression RMSE: 4.644592240580037\n",
      "\n",
      "Random Forest reg RMSE: 4.853849857758906\n",
      "\n",
      "SVM RMSE: 7.057633946704486\n",
      "\n",
      "MLP RMSE: 7.8317692131751375\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#word2vec\n",
    "from tqdm import tqdm_notebook\n",
    "from nltk import word_tokenize\n",
    "from pymagnitude import *\n",
    "\n",
    "\n",
    "glove = Magnitude(\"../downloads/GoogleNews-vectors-negative300.magnitude\")\n",
    "def avg_glove(x):\n",
    "    vectors = []\n",
    "    for title in tqdm_notebook(x):\n",
    "        vectors.append(np.average(glove.query(word_tokenize(title)), axis = 0))\n",
    "    return np.array(vectors)\n",
    "\n",
    "x = avg_glove(X)\n",
    "# x_test = avg_glove(test)\n",
    "\n",
    "get_reg_results(x,y)\n",
    "\n",
    "#word2vec\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "glove = Magnitude(\"../downloads/GoogleNews-vectors-negative300.magnitude\")\n",
    "\n",
    "x = docs\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf.fit(x)\n",
    "# Now lets create a dict so that for every word in the corpus we have a corresponding IDF value\n",
    "idf_dict = dict(zip(tfidf.get_feature_names(), tfidf.idf_))\n",
    "# Same as Avg Glove except instead of doing a regular average, we'll use the IDF values as weights.\n",
    "def tfidf_glove(df):\n",
    "    vectors = []\n",
    "    for title in tqdm_notebook(df):\n",
    "        glove_vectors = glove.query(word_tokenize(title))\n",
    "        weights = [idf_dict.get(word, 1) for word in word_tokenize(title)]\n",
    "        vectors.append(np.average(glove_vectors, axis = 0, weights = weights))\n",
    "    return np.array(vectors)\n",
    "x = tfidf_glove(X)\n",
    "# x_test = tfidf_glove(test)\n",
    "\n",
    "get_reg_results(x,y)\n",
    "\n",
    "#glove\n",
    "from tqdm import tqdm_notebook\n",
    "from nltk import word_tokenize\n",
    "from pymagnitude import *\n",
    "\n",
    "\n",
    "glove = Magnitude(\"../downloads/glove.6B.100d.magnitude\")\n",
    "def avg_glove(x):\n",
    "    vectors = []\n",
    "    for title in tqdm_notebook(x):\n",
    "        vectors.append(np.average(glove.query(word_tokenize(title)), axis = 0))\n",
    "    return np.array(vectors)\n",
    "\n",
    "x = avg_glove(X)\n",
    "# x_test = avg_glove(test)\n",
    "\n",
    "get_reg_results(x,y)\n",
    "\n",
    "#glove\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "glove = Magnitude(\"../downloads/glove.6B.100d.magnitude\")\n",
    "\n",
    "x = docs\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf.fit(x)\n",
    "# Now lets create a dict so that for every word in the corpus we have a corresponding IDF value\n",
    "idf_dict = dict(zip(tfidf.get_feature_names(), tfidf.idf_))\n",
    "# Same as Avg Glove except instead of doing a regular average, we'll use the IDF values as weights.\n",
    "def tfidf_glove(df):\n",
    "    vectors = []\n",
    "    for title in tqdm_notebook(df):\n",
    "        glove_vectors = glove.query(word_tokenize(title))\n",
    "        weights = [idf_dict.get(word, 1) for word in word_tokenize(title)]\n",
    "        vectors.append(np.average(glove_vectors, axis = 0, weights = weights))\n",
    "    return np.array(vectors)\n",
    "x = tfidf_glove(X)\n",
    "# x_test = tfidf_glove(test)\n",
    "\n",
    "get_reg_results(x,y)\n",
    "\n",
    "#glove\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "glove = Magnitude(\"../downloads/glove.840B.300d.magnitude\")\n",
    "\n",
    "x = docs\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf.fit(x)\n",
    "# Now lets create a dict so that for every word in the corpus we have a corresponding IDF value\n",
    "idf_dict = dict(zip(tfidf.get_feature_names(), tfidf.idf_))\n",
    "# Same as Avg Glove except instead of doing a regular average, we'll use the IDF values as weights.\n",
    "def tfidf_glove(df):\n",
    "    vectors = []\n",
    "    for title in tqdm_notebook(df):\n",
    "        glove_vectors = glove.query(word_tokenize(title))\n",
    "        weights = [idf_dict.get(word, 1) for word in word_tokenize(title)]\n",
    "        vectors.append(np.average(glove_vectors, axis = 0, weights = weights))\n",
    "    return np.array(vectors)\n",
    "x = tfidf_glove(X)\n",
    "# x_test = tfidf_glove(test)\n",
    "\n",
    "get_reg_results(x,y)\n",
    "\n",
    "#fasttext\n",
    "from tqdm import tqdm_notebook\n",
    "from nltk import word_tokenize\n",
    "from pymagnitude import *\n",
    "\n",
    "\n",
    "glove = Magnitude(\"../downloads/wiki-news-300d-1M.magnitude\")\n",
    "def avg_glove(x):\n",
    "    vectors = []\n",
    "    for title in tqdm_notebook(x):\n",
    "        vectors.append(np.average(glove.query(word_tokenize(title)), axis = 0))\n",
    "    return np.array(vectors)\n",
    "\n",
    "x = avg_glove(X)\n",
    "# x_test = avg_glove(test)\n",
    "\n",
    "get_reg_results(x,y)\n",
    "\n",
    "#fasttext\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "glove = Magnitude(\"../downloads/wiki-news-300d-1M.magnitude\")\n",
    "\n",
    "x = docs\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf.fit(x)\n",
    "# Now lets create a dict so that for every word in the corpus we have a corresponding IDF value\n",
    "idf_dict = dict(zip(tfidf.get_feature_names(), tfidf.idf_))\n",
    "# Same as Avg Glove except instead of doing a regular average, we'll use the IDF values as weights.\n",
    "def tfidf_glove(df):\n",
    "    vectors = []\n",
    "    for title in tqdm_notebook(df):\n",
    "        glove_vectors = glove.query(word_tokenize(title))\n",
    "        weights = [idf_dict.get(word, 1) for word in word_tokenize(title)]\n",
    "        vectors.append(np.average(glove_vectors, axis = 0, weights = weights))\n",
    "    return np.array(vectors)\n",
    "x = tfidf_glove(X)\n",
    "# x_test = tfidf_glove(test)\n",
    "\n",
    "get_reg_results(x,y)\n",
    "\n",
    "#elmo\n",
    "from tqdm import tqdm_notebook\n",
    "from nltk import word_tokenize\n",
    "from pymagnitude import *\n",
    "\n",
    "\n",
    "glove = Magnitude(\"../downloads/elmo_2x1024_128_2048cnn_1xhighway_weights.magnitude\")\n",
    "def avg_glove(x):\n",
    "    vectors = []\n",
    "    for title in tqdm_notebook(x):\n",
    "        vectors.append(np.average(glove.query(word_tokenize(title)), axis = 0))\n",
    "    return np.array(vectors)\n",
    "\n",
    "x = avg_glove(X)\n",
    "# x_test = avg_glove(test)\n",
    "\n",
    "get_reg_results(x,y)\n",
    "\n",
    "#elmo\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "glove = Magnitude(\"../downloads/elmo_2x1024_128_2048cnn_1xhighway_weights.magnitude\")\n",
    "\n",
    "x = docs\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf.fit(x)\n",
    "# Now lets create a dict so that for every word in the corpus we have a corresponding IDF value\n",
    "idf_dict = dict(zip(tfidf.get_feature_names(), tfidf.idf_))\n",
    "# Same as Avg Glove except instead of doing a regular average, we'll use the IDF values as weights.\n",
    "def tfidf_glove(df):\n",
    "    vectors = []\n",
    "    for title in tqdm_notebook(df):\n",
    "        glove_vectors = glove.query(word_tokenize(title))\n",
    "        weights = [idf_dict.get(word, 1) for word in word_tokenize(title)]\n",
    "        vectors.append(np.average(glove_vectors, axis = 0, weights = weights))\n",
    "    return np.array(vectors)\n",
    "x = tfidf_glove(X)\n",
    "# x_test = tfidf_glove(test)\n",
    "\n",
    "get_reg_results(x,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2      okay.there s a little boy and he s getting he ...\n",
       "36     we ll start with the girl.she s going to the.h...\n",
       "11     all of the action you see going on.okay.this i...\n",
       "30     the children are getting into the cookie jar w...\n",
       "103    well the boy on the chair stool s r is uh fall...\n",
       "                             ...                        \n",
       "53     alright.the little boy girl s reaching up ther...\n",
       "27     hm exc 1963_5292 touching lip.raising arm.lea ...\n",
       "71     um t takin g some cookies.and f fallin g over....\n",
       "66     oh yes.a little girl a and the little boy is g...\n",
       "67     and I will tell you what s g.oh boy.well the l...\n",
       "Name: doc_text, Length: 108, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# bert\n",
    "from sentence_transformers import SentenceTransformer\n",
    "df = pd.read_csv('../csv/train108.csv').sample(frac=1)\n",
    "docs = df['doc_text']\n",
    "y = df['labels']\n",
    "X = docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.46 (+/- 0.12)\n"
     ]
    }
   ],
   "source": [
    "    model = SentenceTransformer('../downloads/bert-base-nli-mean-tokens/')\n",
    "    x = model.encode(X)\n",
    "clf = MLPClassifier(n_iter_no_change=50, max_iter=10000,hidden_layer_sizes=(1000, ))\n",
    "# res = cross_validate(clf, X, y, cv=10,  return_train_score=True) \n",
    "scores = cross_val_score(clf, x, y, cv=10)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
